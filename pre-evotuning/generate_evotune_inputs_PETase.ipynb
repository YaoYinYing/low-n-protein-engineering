{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Inputs for Evotuning eUniRep\n",
    "\n",
    "1. Get input FASTA files from doing PFAM search on wild type protein, then downloading related clans on InterPro. In this case the wild type protein was isPETase, and the PFAM clans downloaded were DLH, cutinases, and lipases. DLH was the best match clan, cutinases and lipases were chosen as they were clans within the same family (A/B fold hydrolases). Out of the 70 clans in the family those 2 were chosen as they are specificially referenced several times across PETase engineering literature.\n",
    "\n",
    "2. Clean the inputs by removing sequences with non-standard residues, anything with length greater than k (in this case k = 600), remove duplicate sequences.\n",
    "\n",
    "3. Calculate levenstein distances from highly desired mutant (i.e. duraPETase) on all clean sequences.\n",
    "\n",
    "4. Generate training, in_domain validation and out_domain validation sets. out_domain validation set is generated first uusing a distribution proportional to distances^4 - taking 10% of the total sequences. Then 10% of the total (11.1% of the remainder) is taken for the in_domain validation set, with the remaining 80% of original = the training set.\n",
    "\n",
    "5. Convert resulting split set of sequences into input format required by UniRep and output to a .fasta.txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions:\n",
    "\n",
    "# read FASTA file:\n",
    "# input: file name\n",
    "# output: names and sequences in the file as an array of dim-2 arrays [name, sequence].\n",
    "def read_fasta(name):\n",
    "    fasta_seqs = SeqIO.parse(open('inputs/' + name + '.fasta.txt'),'fasta')\n",
    "    data = []\n",
    "    for fasta in fasta_seqs:\n",
    "        data.append([fasta.id, str(fasta.seq).strip()])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# write FASTA file:\n",
    "# input: file name; df to write\n",
    "def write_fasta(name, seqs_df):\n",
    "    out_file = open('outputs/' + name + '.fasta.txt', \"w\")\n",
    "    for i in range(len(seqs_df)):\n",
    "        out_file.write('>' + seqs_df.name[i] + '\\n')\n",
    "        out_file.write(seqs_df.sequence[i] + '\\n')\n",
    "    out_file.close()\n",
    "\n",
    "\n",
    "# input: takes in a sequence\n",
    "# output: True if a sequence contains only standard amino acids, returns False if contains non-standard ones.\n",
    "def validate(seq, pattern=re.compile(r'^[FIWLVMYCATHGSQRKNEPD]+$')):\n",
    "    if (pattern.match(seq)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "    \n",
    "# Remove sequences longer than k residues and with non-standard residues\n",
    "# inputs: seqs_df = dataframe of name, sequence; k = max lenght of residues to keep\n",
    "# output: cleaned dataframe\n",
    "def clean(seqs_df, k):\n",
    "    # remove sequences with length > 1000 AA's\n",
    "    rows2drop = []\n",
    "    for i in range(len(seqs_df)):\n",
    "        if (len(seqs_df.sequence[i]) > k):\n",
    "            rows2drop.append(i)\n",
    "\n",
    "    print('Total number of sequences dropped:', len(rows2drop))\n",
    "\n",
    "    seqs_df = seqs_df.drop(rows2drop).reset_index().drop('index', axis=1)\n",
    "\n",
    "    print('Total number of sequences remaining:', len(seqs_df))\n",
    "    \n",
    "    # remove sequences with invalid AA residues\n",
    "    # valid_alphabet = ['F','I','W','L','V','M','Y','C','A','T','H','G','S','Q','R','K','N','E','P','D']\n",
    "    invalid_seqs = []\n",
    "\n",
    "    for i in range(len(seqs_df)):\n",
    "        if (not validate(seqs_df.sequence[i])):\n",
    "            invalid_seqs.append(i)\n",
    "\n",
    "    print('Total number of sequences dropped:', len(invalid_seqs))\n",
    "\n",
    "    seqs_df = seqs_df.drop(invalid_seqs).reset_index().drop('index', axis=1)\n",
    "\n",
    "    print('Total number of sequences remaining:', len(seqs_df))\n",
    "    \n",
    "    \n",
    "    seqs_df = seqs_df.drop_duplicates(subset='sequence').reset_index().drop('index', axis=1)\n",
    "\n",
    "    print('Total sequences remaining after duplicate removal', len(seqs_df))\n",
    "\n",
    "    \n",
    "    return seqs_df\n",
    "\n",
    "\n",
    "# calculate the Levenstein distance of mulitple sequences to a target sequence\n",
    "# also plots a histogram of distances\n",
    "# inputs: t_seq = target sequence; seqs_df = dataframe of sequences;\n",
    "# num_bins = bins for histogram; hist_range = range for histogram\n",
    "# outputs: numpy array of distances\n",
    "def lev_dist(t_seq, seqs_df, num_bins=20, hist_range=(0,350)):\n",
    "    distances = []\n",
    "    for i in range(len(seqs_df)):\n",
    "        distances.append(distance(t_seq, seqs_df.sequence[i]))\n",
    "    distances = np.array(distances)\n",
    "\n",
    "    mean_dist = np.mean(distances)\n",
    "    median_dist = np.median(distances)\n",
    "    min_dist = np.min(distances)\n",
    "    max_dist = np.max(distances)\n",
    "    \n",
    "    print(\"Mean Levenstein distance:\", mean_dist)\n",
    "    print(\"Median Levenstein distance:\", mean_dist)\n",
    "    print(\"Min Levenstein distance:\", min_dist)\n",
    "    print(\"Max Levenstein distance:\", max_dist)\n",
    "\n",
    "    \n",
    "    # histogram of Levenstein distances from target sequence\n",
    "    plt.clf()\n",
    "    plt.hist(distances, bins=num_bins, range=hist_range)\n",
    "    plt.show()\n",
    "    \n",
    "    return distances\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "File formatting note.\n",
    "Data should be preprocessed as a sequence of comma-seperated ints with\n",
    "sequences  /n seperated\n",
    "\"\"\"\n",
    "\n",
    "# Lookup tables\n",
    "aa_to_int = {\n",
    "    'M':1,\n",
    "    'R':2,\n",
    "    'H':3,\n",
    "    'K':4,\n",
    "    'D':5,\n",
    "    'E':6,\n",
    "    'S':7,\n",
    "    'T':8,\n",
    "    'N':9,\n",
    "    'Q':10,\n",
    "    'C':11,\n",
    "    'U':12,\n",
    "    'G':13,\n",
    "    'P':14,\n",
    "    'A':15,\n",
    "    'V':16,\n",
    "    'I':17,\n",
    "    'F':18,\n",
    "    'Y':19,\n",
    "    'W':20,\n",
    "    'L':21,\n",
    "    'O':22, #Pyrrolysine\n",
    "    'X':23, # Unknown\n",
    "    'Z':23, # Glutamic acid or GLutamine\n",
    "    'B':23, # Asparagine or aspartic acid\n",
    "    'J':23, # Leucine or isoleucine\n",
    "    'start':24,\n",
    "    'stop':25,\n",
    "}\n",
    "\n",
    "int_to_aa = {value:key for key, value in aa_to_int.items()}\n",
    "\n",
    "def get_aa_to_int():\n",
    "    \"\"\"\n",
    "    Get the lookup table (for easy import)\n",
    "    \"\"\"\n",
    "    return aa_to_int\n",
    "\n",
    "def get_int_to_aa():\n",
    "    \"\"\"\n",
    "    Get the lookup table (for easy import)\n",
    "    \"\"\"\n",
    "    return int_to_aa\n",
    "    \n",
    "def aa_seq_to_int(s):\n",
    "    \"\"\"\n",
    "    Return the int sequence as a list for a given string of amino acids\n",
    "    \"\"\"\n",
    "    return [24] + [aa_to_int[a] for a in s] + [25]\n",
    "\n",
    "def int_seq_to_aa(s):\n",
    "    \"\"\"\n",
    "    Return the int sequence as a list for a given string of amino acids\n",
    "    \"\"\"\n",
    "    return \"\".join([int_to_aa[i] for i in s])\n",
    "\n",
    "    \n",
    "def format_seq(seq,stop=False):\n",
    "    \"\"\"\n",
    "    Takes an amino acid sequence, returns a list of integers in the codex of the babbler.\n",
    "    Here, the default is to strip the stop symbol (stop=False) which would have \n",
    "    otherwise been added to the end of the sequence. If you are trying to generate\n",
    "    a rep, do not include the stop. It is probably best to ignore the stop if you are\n",
    "    co-tuning the babbler and a top model as well.\n",
    "    \"\"\"\n",
    "    if stop:\n",
    "        int_seq = aa_seq_to_int(seq.strip())\n",
    "    else:\n",
    "        int_seq = aa_seq_to_int(seq.strip())[:-1]\n",
    "    return int_seq\n",
    "\n",
    "def is_valid_seq(seq, max_len=2000):\n",
    "    \"\"\"\n",
    "    True if seq is valid for the babbler, False otherwise.\n",
    "    \"\"\"\n",
    "    l = len(seq)\n",
    "    valid_aas = \"MRHKDESTNQCUGPAVIFYWLO\"\n",
    "    if (l < max_len) and set(seq) <= set(valid_aas):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def fasta_to_input(in_path):\n",
    "    source = SeqIO.parse(in_path + '.fasta.txt','fasta')\n",
    "    with open(in_path + \"_formatted.fasta.txt\", \"w\") as destination:\n",
    "        for seq in fasta_seqs:\n",
    "            seq = seq.strip()\n",
    "            if is_valid_seq(seq) and len(seq) < 275: \n",
    "                formatted = \",\".join(map(str,format_seq(seq)))\n",
    "                destination.write(formatted)\n",
    "                destination.write('\\n')\n",
    "\n",
    "def seqs_to_input(name, in_seqs, stop=False):\n",
    "    with open('outputs/' + name + \"_formatted.fasta.txt\", \"w\") as destination:\n",
    "        for seq in in_seqs:\n",
    "            seq = seq.strip()\n",
    "            if is_valid_seq(seq): \n",
    "                formatted = \",\".join(map(str,format_seq(seq, stop=stop)))\n",
    "                destination.write(formatted)\n",
    "                destination.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input sequences: 95886\n",
      "Total number of sequences dropped: 12679\n",
      "Total number of sequences remaining: 83207\n",
      "Total number of sequences dropped: 845\n",
      "Total number of sequences remaining: 82362\n",
      "Total sequences remaining after duplicate removal 74050\n"
     ]
    }
   ],
   "source": [
    "# input FASTA files:\n",
    "in_fasta_1 = 'dlh'\n",
    "in_fasta_2 = 'cutinase'\n",
    "in_fasta_3 = 'lipase'\n",
    "in_fasta_4 = 'ab_hydrolase_5'\n",
    "\n",
    "# put sequences into a pandas dataframes\n",
    "sequences_1_df = pd.DataFrame(read_fasta(in_fasta_1), columns = ['name', 'sequence'])\n",
    "sequences_2_df = pd.DataFrame(read_fasta(in_fasta_2), columns = ['name', 'sequence'])\n",
    "sequences_3_df = pd.DataFrame(read_fasta(in_fasta_3), columns = ['name', 'sequence'])\n",
    "sequences_4_df = pd.DataFrame(read_fasta(in_fasta_4), columns = ['name', 'sequence'])\n",
    "\n",
    "# concatinate the dataframes vertically (i.e. stack them)\n",
    "sequences_df = pd.concat([sequences_1_df, sequences_2_df, sequences_3_df, sequences_4_df], axis=0).reset_index().drop('index', axis=1)\n",
    "\n",
    "print('Total number of input sequences:', len(sequences_df))\n",
    "\n",
    "# clean the sequences:\n",
    "# the number here is the AA length we want - set to 600 as that was what was used for TEM-1\n",
    "clean_seqs_df = clean(sequences_df, 350)\n",
    "\n",
    "# save clean sequences as a .fasta.txt file\n",
    "write_fasta('all_sequences_clean', clean_seqs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duraPETase\n",
      "MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEASAGPFTVRSFTVSRPSGYGAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTFDYPSSRSSQQMAALRQVASLNGDSSSPIYGKVDTARMGVMGHSMGGGASLRSAANNPSLKAAIPQAPWDSQTNFSSVTVPTLIFACENDSIAPVNSHALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTAVSDFRTANCS\n"
     ]
    }
   ],
   "source": [
    "# load target sequence\n",
    "target_fasta = 'duraPETase'\n",
    "targets = read_fasta(target_fasta)\n",
    "print(targets[0][0])\n",
    "print(targets[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Levenstein distance: 232.2713031735314\n",
      "Median Levenstein distance: 232.2713031735314\n",
      "Min Levenstein distance: 10\n",
      "Max Levenstein distance: 292\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a2adb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate levenstein distance from chosen target sequence\n",
    "distances = lev_dist(targets[0][1], clean_seqs_df, 30, (0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# partition into the training and 2 validation sets:\n",
    "\n",
    "clean_seqs_df_copy = clean_seqs_df.copy()\n",
    "out_domain_val_set = clean_seqs_df_copy.sample(frac=0.1, weights=distances**4, random_state=17)\n",
    "remainder_df = clean_seqs_df_copy.drop(out_domain_val_set.index)\n",
    "#train_set = remainder_df.sample(frac=0.889, random_state=17)\n",
    "#in_domain_val_set = remainder_df.drop(train_set.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of domain validation set size: 7405\n",
      "Training set size: 66645\n"
     ]
    }
   ],
   "source": [
    "# set check sizes\n",
    "print('Out of domain validation set size:', len(out_domain_val_set))\n",
    "#print('In domain validation set size:', len(in_domain_val_set))\n",
    "print('Training set size:', len(remainder_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to fasta file formats:\n",
    "\n",
    "write_fasta('train_set', remainder_df.reset_index().drop('index', axis=1))\n",
    "write_fasta('out_domain_val_set', out_domain_val_set.reset_index().drop('index', axis=1))\n",
    "#write_fasta('in_domain_val_set', in_domain_val_set.reset_index().drop('index', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNUSED - AS SWITCHED TO JAX.\n",
    "# convert to input representation needed by eUniRep and output as fasta text files\n",
    "\n",
    "#seqs_to_input('train_set', train_set.sequence, stop=True)\n",
    "#seqs_to_input('out_domain_val_set', out_domain_val_set.sequence, stop=True)\n",
    "#seqs_to_input('in_domain_val_set', in_domain_val_set.sequence, stop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
